[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![FAME Lab](https://img.shields.io/badge/Bioinformatics-EdwardsLab-03A9F4)](https://fame.flinders.edu.au/)


# Phynteny

## Phynteny: Synteny-based annotation of viral genes 

## Usage 

## Training Phynteny 
Phynteny has already been trained for you on a dataset containing over 1 million prophages! However, If you feel inclined to train Phynteny yourself you can. <br> 
Phynteny is trained using genbank files containing PHROG annotations such as those generated by [pharokka](https://github.com/gbouras13/pharokka). 

Use `-i` as a text file with the paths to the genbank files 

```
python generate_training_data.py -i genbank_files.txt -o training_dataset.pkl -max_genes 120 -gene_cat 4 -c 11 
```
This command generates training data including prophages with a maximum of 120 genes where each contains at least four different PHROG categories. The output data is separated into 11 different chunks which can be used for training with k-fold validation. 

Using this data, the model can be trained using the script #TODO 

**WARNING** Without a GPU training will take a very very long time! 

## Bugs and Suggestions 
If you break Phynteny or would like to make any suggestions please open an issue or email me at susie.grigson@flinders.edu.au 


## Citation 
TODO 
